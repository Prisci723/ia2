{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67a0d38ee58544e5b3ab2248428a2691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8e8f9e3bbee4e6d9cd54d1dcc1e29e1",
              "IPY_MODEL_6180d8b0c7c3404687b1ae8e353cbc1c",
              "IPY_MODEL_c245982d48ab4e50893afd03730d0e79"
            ],
            "layout": "IPY_MODEL_22a4b003c9754f00b38249307da26261"
          }
        },
        "d8e8f9e3bbee4e6d9cd54d1dcc1e29e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e780ad19b242eea5017c9b56a1e29c",
            "placeholder": "​",
            "style": "IPY_MODEL_4d772a3bcac6479d8d2be679886e5363",
            "value": "Training:   0%"
          }
        },
        "6180d8b0c7c3404687b1ae8e353cbc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a274c940b4e34b04999f016568cf2b90",
            "max": 8121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a60765382d8d4d208894ef1a9e5dfefc",
            "value": 0
          }
        },
        "c245982d48ab4e50893afd03730d0e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d236164d79643f5b75c54e1c9517d78",
            "placeholder": "​",
            "style": "IPY_MODEL_847464c212f84c4bb2c95f27fdec77ee",
            "value": " 0/8121 [00:00&lt;?, ?it/s]"
          }
        },
        "22a4b003c9754f00b38249307da26261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e780ad19b242eea5017c9b56a1e29c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d772a3bcac6479d8d2be679886e5363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a274c940b4e34b04999f016568cf2b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60765382d8d4d208894ef1a9e5dfefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d236164d79643f5b75c54e1c9517d78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847464c212f84c4bb2c95f27fdec77ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPhKHsxvMNEq",
        "outputId": "318ed4a1-b07a-40c0-99aa-f2983787c86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss7OY-y9hvNh",
        "outputId": "5b81e366-2f2a-486e-82cb-b68dac4c623b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "0PgO92b7OTJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sRWL00l3dOzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CodeGenerationDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        text = item['text']\n",
        "        code = item['code']\n",
        "\n",
        "        # Combine text and code\n",
        "        combined = f\"{text} <CODE> {code}\"\n",
        "\n",
        "        # Tokenize with proper padding and truncation\n",
        "        encoding = self.tokenizer(\n",
        "            combined,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Remove the batch dimension added by tokenizer\n",
        "        input_ids = encoding['input_ids'].squeeze(0)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Create labels (shifted input_ids)\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        # Shift labels to the right by 1 and set first token to -100\n",
        "        labels[:-1] = input_ids[1:]\n",
        "        labels[-1] = -100  # Ignore last token prediction\n",
        "\n",
        "        # Mask padding tokens in labels with -100\n",
        "        labels[attention_mask == 0] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "def create_dataloaders(dataset, tokenizer, batch_size=16, max_length=512, train_split=0.8):\n",
        "    \"\"\"Create train and validation dataloaders\"\"\"\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_size = int(len(dataset['train']) * train_split)\n",
        "    train_data = dataset['train'].select(range(train_size))\n",
        "    val_data = dataset['train'].select(range(train_size, len(dataset['train'])))\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CodeGenerationDataset(train_data, tokenizer, max_length)\n",
        "    val_dataset = CodeGenerationDataset(val_data, tokenizer, max_length)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "qx6UwyWfdPv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    get_scheduler,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    AutoTokenizer\n",
        ")\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "64nRXvs2gFL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingLogger:\n",
        "    def __init__(self, log_dir='runs'):\n",
        "        self.log_dir = Path(log_dir) / datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        self.writer = SummaryWriter(self.log_dir)\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def log_step(self, train_loss=None, val_loss=None, lr=None, step=0):\n",
        "        if train_loss is not None:\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.writer.add_scalar('Loss/train', train_loss, step)\n",
        "\n",
        "        if val_loss is not None:\n",
        "            self.val_losses.append(val_loss)\n",
        "            self.writer.add_scalar('Loss/validation', val_loss, step)\n",
        "\n",
        "        if lr is not None:\n",
        "            self.learning_rates.append(lr)\n",
        "            self.writer.add_scalar('Learning_rate', lr, step)\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        # Plot losses\n",
        "        ax1.plot(self.train_losses, label='Train')\n",
        "        ax1.plot(self.val_losses, label='Validation')\n",
        "        ax1.set_title('Losses')\n",
        "        ax1.set_xlabel('Step')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.legend()\n",
        "\n",
        "        # Plot learning rate\n",
        "        ax2.plot(self.learning_rates)\n",
        "        ax2.set_title('Learning Rate')\n",
        "        ax2.set_xlabel('Step')\n",
        "\n",
        "        # Plot loss distributions\n",
        "        sns.kdeplot(data=self.train_losses, ax=ax3, label='Train')\n",
        "        sns.kdeplot(data=self.val_losses, ax=ax3, label='Validation')\n",
        "        ax3.set_title('Loss Distribution')\n",
        "        ax3.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.log_dir / 'training_metrics.png')\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "zyKsMFFchE0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.best_weights = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "            return False\n",
        "\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "EF--JFblhJVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeGenerationModel(nn.Module):\n",
        "    def __init__(self, model_name=\"microsoft/CodeGPT-small-py\", dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "        # Add dropout for regularization\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Freeze the first n layers of the transformer\n",
        "        self._freeze_base_layers()\n",
        "\n",
        "    def _freeze_base_layers(self, num_layers_to_freeze=6):\n",
        "        \"\"\"Freeze the first n layers of the transformer\"\"\"\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the last few layers for fine-tuning\n",
        "        for param in self.model.transformer.h[num_layers_to_freeze:].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # Always unfreeze the final layer for task-specific adaptation\n",
        "        for param in self.model.lm_head.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "RqsJArjXfivf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    patience=7,\n",
        "    save_dir='checkpoints',\n",
        "    device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Create save directory\n",
        "    save_dir = Path(save_dir)\n",
        "    save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Initialize logger\n",
        "    logger = TrainingLogger()\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=patience)\n",
        "\n",
        "    # Move model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize optimizer\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    # Initialize learning rate scheduler\n",
        "    scheduler = OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=learning_rate,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.3,\n",
        "        anneal_strategy='cos'\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    global_step = 0\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc='Training')\n",
        "        for batch in train_pbar:\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Log metrics\n",
        "            train_losses.append(loss.item())\n",
        "            current_lr = scheduler.get_last_lr()[0]\n",
        "\n",
        "            logger.log_step(\n",
        "                train_loss=loss.item(),\n",
        "                lr=current_lr,\n",
        "                step=global_step\n",
        "            )\n",
        "\n",
        "            # Update progress bar\n",
        "            train_pbar.set_postfix({\n",
        "                'loss': f\"{loss.item():.4f}\",\n",
        "                'lr': f\"{current_lr:.2e}\"\n",
        "            })\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc='Validation')\n",
        "            for batch in val_pbar:\n",
        "                batch = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**batch)\n",
        "                loss = outputs.loss\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "                val_pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "\n",
        "        # Calculate average losses\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "\n",
        "        # Log validation metrics\n",
        "        logger.log_step(val_loss=avg_val_loss, step=global_step)\n",
        "\n",
        "        print(f\"\\nAvg train loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Avg validation loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint if best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "            }, save_dir / 'best_model.pt')\n",
        "\n",
        "        # Regular checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'train_loss': avg_train_loss,\n",
        "            'val_loss': avg_val_loss,\n",
        "        }, save_dir / f'checkpoint_epoch_{epoch+1}.pt')\n",
        "\n",
        "        # Early stopping check\n",
        "        if early_stopping(avg_val_loss, model):\n",
        "            print(\"\\nEarly stopping triggered!\")\n",
        "            model.load_state_dict(early_stopping.best_weights)\n",
        "            break\n",
        "\n",
        "    # Final plots\n",
        "    logger.plot_metrics()\n",
        "\n",
        "    return model, logger"
      ],
      "metadata": {
        "id": "HgJ704EjhSFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"codeparrot/xlcost-text-to-code\", \"Python-snippet-level\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/CodeGPT-small-py\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader, val_loader = create_dataloaders(\n",
        "    dataset=dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=5,\n",
        "    max_length=512\n",
        ")\n",
        "\n",
        "# Initialize and train model\n",
        "model = CodeGenerationModel()\n",
        "trained_model, logger = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    patience=7,\n",
        "    save_dir='/content/drive/MyDrive/SIS421/NLP/CheckpointTranslator'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216,
          "referenced_widgets": [
            "67a0d38ee58544e5b3ab2248428a2691",
            "d8e8f9e3bbee4e6d9cd54d1dcc1e29e1",
            "6180d8b0c7c3404687b1ae8e353cbc1c",
            "c245982d48ab4e50893afd03730d0e79",
            "22a4b003c9754f00b38249307da26261",
            "b2e780ad19b242eea5017c9b56a1e29c",
            "4d772a3bcac6479d8d2be679886e5363",
            "a274c940b4e34b04999f016568cf2b90",
            "a60765382d8d4d208894ef1a9e5dfefc",
            "4d236164d79643f5b75c54e1c9517d78",
            "847464c212f84c4bb2c95f27fdec77ee"
          ]
        },
        "id": "WfDuuqNZhhXv",
        "outputId": "4c4de9a0-50a6-478e-dae6-363cb079cf45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/8121 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a0d38ee58544e5b3ab2248428a2691"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Fe8JVEWsdaL_"
      }
    }
  ]
}